{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15cb0974-34b0-4a23-8c5e-70c2569f5187",
   "metadata": {},
   "source": [
    "Snakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8c636a-9e1c-4780-adf7-8184822a3862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20226, 11)\n",
      "Index(['Request Number', 'Date Opened', 'Request ', 'Description',\n",
      "       'Incident Address', 'Zip Code', 'Trash Hauler', 'Trash Route',\n",
      "       'Council District', 'State Plan X', 'State Plan Y'],\n",
      "      dtype='object')\n",
      "Request Number        int64\n",
      "Date Opened          object\n",
      "Request              object\n",
      "Description          object\n",
      "Incident Address     object\n",
      "Zip Code            float64\n",
      "Trash Hauler         object\n",
      "Trash Route          object\n",
      "Council District    float64\n",
      "State Plan X        float64\n",
      "State Plan Y        float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20226 entries, 0 to 20225\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Request Number    20226 non-null  int64  \n",
      " 1   Date Opened       20226 non-null  object \n",
      " 2   Request           20226 non-null  object \n",
      " 3   Description       20195 non-null  object \n",
      " 4   Incident Address  20217 non-null  object \n",
      " 5   Zip Code          20151 non-null  float64\n",
      " 6   Trash Hauler      19325 non-null  object \n",
      " 7   Trash Route       19279 non-null  object \n",
      " 8   Council District  20177 non-null  float64\n",
      " 9   State Plan X      20198 non-null  float64\n",
      " 10  State Plan Y      20198 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request Number</th>\n",
       "      <th>Date Opened</th>\n",
       "      <th>Request</th>\n",
       "      <th>Description</th>\n",
       "      <th>Incident Address</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Trash Hauler</th>\n",
       "      <th>Trash Route</th>\n",
       "      <th>Council District</th>\n",
       "      <th>State Plan X</th>\n",
       "      <th>State Plan Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25270</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Backdoor</td>\n",
       "      <td>house with the wheel chair ramp, they share dr...</td>\n",
       "      <td>3817 Crouch Dr</td>\n",
       "      <td>37207.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>3205</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.727970e+06</td>\n",
       "      <td>686779.478089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25274</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>Curb/Trash miss Tuesday.</td>\n",
       "      <td>4028 Clarksville Pike</td>\n",
       "      <td>37218.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>4202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.721259e+06</td>\n",
       "      <td>685444.799565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25276</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>Curb/trash miss Tuesday.</td>\n",
       "      <td>6528 Thunderbird Dr</td>\n",
       "      <td>37209.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>4205</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.707027e+06</td>\n",
       "      <td>659887.471571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25307</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>missed</td>\n",
       "      <td>2603 old matthews rd</td>\n",
       "      <td>37207.0</td>\n",
       "      <td>WASTE IND</td>\n",
       "      <td>2206</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.735692e+06</td>\n",
       "      <td>685027.245923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25312</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>Missed the even side of the road.</td>\n",
       "      <td>604 croley dr</td>\n",
       "      <td>37209.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>4203</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.710186e+06</td>\n",
       "      <td>664205.101066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Request Number Date Opened                              Request   \\\n",
       "0           25270    11/01/17                      Trash - Backdoor   \n",
       "1           25274    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "2           25276    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "3           25307    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "4           25312    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "\n",
       "                                         Description       Incident Address  \\\n",
       "0  house with the wheel chair ramp, they share dr...         3817 Crouch Dr   \n",
       "1                           Curb/Trash miss Tuesday.  4028 Clarksville Pike   \n",
       "2                           Curb/trash miss Tuesday.    6528 Thunderbird Dr   \n",
       "3                                             missed   2603 old matthews rd   \n",
       "4                  Missed the even side of the road.          604 croley dr   \n",
       "\n",
       "   Zip Code Trash Hauler Trash Route  Council District  State Plan X  \\\n",
       "0   37207.0    RED RIVER        3205               2.0  1.727970e+06   \n",
       "1   37218.0    RED RIVER        4202               1.0  1.721259e+06   \n",
       "2   37209.0    RED RIVER        4205              20.0  1.707027e+06   \n",
       "3   37207.0    WASTE IND        2206               2.0  1.735692e+06   \n",
       "4   37209.0    RED RIVER        4203              20.0  1.710186e+06   \n",
       "\n",
       "    State Plan Y  \n",
       "0  686779.478089  \n",
       "1  685444.799565  \n",
       "2  659887.471571  \n",
       "3  685027.245923  \n",
       "4  664205.101066  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "trash_df = pd.read_csv('../data/trash_hauler_report.csv')\n",
    "#Explore the data\n",
    "print(trash_df.shape)\n",
    "print(trash_df.columns)\n",
    "print(trash_df.dtypes)\n",
    "print(trash_df.info())\n",
    "trash_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b005d40-55ab-4567-9067-9d7a63c851f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed extra spaces in some of the raw data, so this will clean up leading/trailing and extra spaces.\n",
    "\n",
    "#Clean only columns with object (string) type\n",
    "str_cols = trash_df.select_dtypes(include='object').columns\n",
    "\n",
    "#Clean and normalize whitespace in each string column\n",
    "for col in str_cols:\n",
    "    trash_df[col] = trash_df[col].astype(str).apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "#Clean column whitespace\n",
    "trash_df.columns = trash_df.columns.str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67339f44-3d1f-421a-a04a-edcea5c8261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Request\n",
       "Trash - Curbside/Alley Missed Pickup    15028\n",
       "Trash - Backdoor                         2629\n",
       "Trash Collection Complaint               2312\n",
       "Damage to Property                        257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make 'Request' column into a category\n",
    "trash_df['Request'] = trash_df['Request'].astype('category')\n",
    "trash_df['Request'].cat.categories\n",
    "trash_df['Request'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e39f62-349f-47b1-a0f3-aac657b428ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all lowercase so matches are consistent\n",
    "trash_df['description_clean'] = trash_df['Description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e17e34-c049-451a-997a-2d0c623de155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To help ensure data is complete, this creates a new Street Name column with only the street names (no address numbers)\n",
    "#Then if data is missing (Zip, Hauler, Route, District etc) it will complete the missing data based on the assumption that all addresses on the same street\n",
    "#uses the same Zip, Hauler, Route, District etc). It will complete any missing data for Incidents on the same Street Name.\n",
    "#It normalizes the new Street Name to USPS naming conventions so they can be easily grouped if needed.\n",
    "\n",
    "# USPS street suffix abbreviations\n",
    "suffix_map = {\n",
    "    'avenue': 'Ave', 'av': 'Ave', 'av.': 'Ave',\n",
    "    'road': 'Rd', 'rd': 'Rd',\n",
    "    'street': 'St', 'st': 'St',\n",
    "    'boulevard': 'Blvd', 'blvd': 'Blvd',\n",
    "    'drive': 'Dr', 'dr': 'Dr',\n",
    "    'court': 'Ct', 'ct': 'Ct',\n",
    "    'lane': 'Ln', 'ln': 'Ln',\n",
    "    'place': 'Pl', 'pl': 'Pl',\n",
    "    'circle': 'Cir', 'cir': 'Cir',\n",
    "    'trail': 'Trl', 'trl': 'Trl',\n",
    "    'parkway': 'Pkwy', 'pkwy': 'Pkwy',\n",
    "    'terrace': 'Ter', 'ter': 'Ter',\n",
    "    'way': 'Way',\n",
    "    'loop': 'Loop'\n",
    "}\n",
    "\n",
    "# USPS directional abbreviations\n",
    "direction_map = {\n",
    "    'north': 'N', 'n.': 'N', 'n': 'N',\n",
    "    'south': 'S', 's.': 'S', 's': 'S',\n",
    "    'east': 'E', 'e.': 'E', 'e': 'E',\n",
    "    'west': 'W', 'w.': 'W', 'w': 'W'\n",
    "}\n",
    "\n",
    "#Full address normalization (keeps number)\n",
    "def normalize_address(address):\n",
    "    if pd.isnull(address):\n",
    "        return None\n",
    "    address = str(address).strip().lower()\n",
    "    words = address.split()\n",
    "    result = []\n",
    "    for word in words:\n",
    "        clean_word = re.sub(r'[^\\w]', '', word)\n",
    "        if clean_word in direction_map:\n",
    "            result.append(direction_map[clean_word])\n",
    "        elif clean_word in suffix_map:\n",
    "            result.append(suffix_map[clean_word])\n",
    "        else:\n",
    "            result.append(clean_word.capitalize())\n",
    "    return ' '.join(result)\n",
    "\n",
    "#Street name normalization (removes house number first)\n",
    "def normalize_street(address):\n",
    "    if pd.isnull(address):\n",
    "        return None\n",
    "    address = str(address).strip()\n",
    "    # Remove leading house number\n",
    "    address_no_number = re.sub(r'^\\s*\\d+[^\\s]*\\s+', '', address)\n",
    "    return normalize_address(address_no_number)\n",
    "\n",
    "#Apply to DataFrame\n",
    "trash_df['Street Name'] = trash_df['Incident Address'].apply(normalize_street)\n",
    "trash_df['Incident Address'] = trash_df['Incident Address'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4d2471-11f8-4d9f-aae1-c829f60fe7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed that several other descriptions mention missed pickups in the Description column.\n",
    "#This is a list of keywords it finds in the event that the Request is not properly labeled as a Missed Pickup.\n",
    "#More keywords could be added if noticed in the raw data.\n",
    "\n",
    "import re\n",
    "\n",
    "keywords = [\n",
    "    'miss', 'missed', 'not picked up', 'not collected', 'no pickup',\n",
    "    'never came', 'did not collect', 'didn’t pick up', 'did not pick up'\n",
    "]\n",
    "\n",
    "pattern = '|'.join(re.escape(word) for word in keywords)\n",
    "\n",
    "is_missed_request = trash_df['Request'].str.contains(\"missed pickup\", case=False, na=False)\n",
    "is_missed_description = trash_df['description_clean'].str.contains(pattern, na=False)\n",
    "\n",
    "missed_pickups = trash_df[is_missed_request | is_missed_description]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cda4e75-2c80-4f81-a0d9-27398d35c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed that some entries seemed to be duplicates based on the date opened and the Incident Address in the raw data.\n",
    "#This filters out any Requests that may have been submitted multiple times for the same Date/Incident Address\n",
    "missed_pickups = missed_pickups.copy()\n",
    "missed_pickups['Date Opened'] = pd.to_datetime(\n",
    "    missed_pickups['Date Opened'], format='%m/%d/%y', errors='coerce'\n",
    ")\n",
    "\n",
    "unique_missed = missed_pickups.drop_duplicates(subset=['Incident Address', 'Date Opened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e1f661-5ed2-4234-b5b5-2e9c78aced45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed some data was missing, i.e. Zip Code, Trash Hauler, Route, District etc.\n",
    "#This groups by the newly created 'Street Name' column and uses the infer data for the Street Name to fill in incomplete data if other instances of the same Street.\n",
    "cols_to_fill = ['Zip Code', 'Trash Hauler', 'Trash Route', 'Council District']\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    trash_df[col] = trash_df.groupby('Street Name')[col].transform(lambda x: x.ffill().bfill())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e780d93e-04ac-4aab-8fdf-42448478bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This exports the cleaned data to a CSV file. The output only includes unique missed pickups based on Request and/or keywords in Description columns.\n",
    "\n",
    "#Filter based on Request type or keywords in Description\n",
    "keywords = [\n",
    "    'miss', 'missed', 'not picked up', 'not collected', 'no pickup',\n",
    "    'never came', 'did not collect', 'didn’t pick up', 'did not pick up'\n",
    "]\n",
    "pattern = '|'.join(re.escape(word) for word in keywords)\n",
    "\n",
    "is_missed_request = trash_df['Request'].str.contains(\"missed pickup\", case=False, na=False)\n",
    "is_missed_description = trash_df['description_clean'].str.contains(pattern, na=False)\n",
    "\n",
    "missed_pickups = trash_df[is_missed_request | is_missed_description].copy()\n",
    "\n",
    "#Normalize data\n",
    "missed_pickups['Date Opened'] = pd.to_datetime(missed_pickups['Date Opened'], format='%m/%d/%y', errors='coerce')\n",
    "\n",
    "#Remove same-day duplicates\n",
    "unique_missed = missed_pickups.drop_duplicates(subset=['Incident Address', 'Date Opened']).copy()\n",
    "\n",
    "#Normalize Street Name\n",
    "unique_missed['Street Name'] = unique_missed['Incident Address'].apply(normalize_street)\n",
    "\n",
    "#Fill missing data based on same Street Names\n",
    "cols_to_fill = ['Zip Code', 'Trash Hauler', 'Trash Route', 'Council District']\n",
    "for col in cols_to_fill:\n",
    "    unique_missed[col] = unique_missed.groupby('Street Name')[col].transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "#Export to /data folder\n",
    "unique_missed.to_csv('../data/cleaned_missed_pickups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc342bcd-7116-4802-91bf-8b6a1da21f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Request Number', 'Date Opened', 'Request', 'Description',\n",
      "       'Incident Address', 'Zip Code', 'Trash Hauler', 'Trash Route',\n",
      "       'Council District', 'State Plan X', 'State Plan Y', 'description_clean',\n",
      "       'Street Name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(trash_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c763f8-25f2-43a6-b946-1b8c7e4d3105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-geospatial] *",
   "language": "python",
   "name": "conda-env-anaconda3-geospatial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
