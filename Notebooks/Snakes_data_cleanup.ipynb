{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15cb0974-34b0-4a23-8c5e-70c2569f5187",
   "metadata": {},
   "source": [
    "Snakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8c636a-9e1c-4780-adf7-8184822a3862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20226, 11)\n",
      "Index(['Request Number', 'Date Opened', 'Request ', 'Description',\n",
      "       'Incident Address', 'Zip Code', 'Trash Hauler', 'Trash Route',\n",
      "       'Council District', 'State Plan X', 'State Plan Y'],\n",
      "      dtype='object')\n",
      "Request Number        int64\n",
      "Date Opened          object\n",
      "Request              object\n",
      "Description          object\n",
      "Incident Address     object\n",
      "Zip Code            float64\n",
      "Trash Hauler         object\n",
      "Trash Route          object\n",
      "Council District    float64\n",
      "State Plan X        float64\n",
      "State Plan Y        float64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20226 entries, 0 to 20225\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Request Number    20226 non-null  int64  \n",
      " 1   Date Opened       20226 non-null  object \n",
      " 2   Request           20226 non-null  object \n",
      " 3   Description       20195 non-null  object \n",
      " 4   Incident Address  20217 non-null  object \n",
      " 5   Zip Code          20151 non-null  float64\n",
      " 6   Trash Hauler      19325 non-null  object \n",
      " 7   Trash Route       19279 non-null  object \n",
      " 8   Council District  20177 non-null  float64\n",
      " 9   State Plan X      20198 non-null  float64\n",
      " 10  State Plan Y      20198 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request Number</th>\n",
       "      <th>Date Opened</th>\n",
       "      <th>Request</th>\n",
       "      <th>Description</th>\n",
       "      <th>Incident Address</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Trash Hauler</th>\n",
       "      <th>Trash Route</th>\n",
       "      <th>Council District</th>\n",
       "      <th>State Plan X</th>\n",
       "      <th>State Plan Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25270</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Backdoor</td>\n",
       "      <td>house with the wheel chair ramp, they share dr...</td>\n",
       "      <td>3817 Crouch Dr</td>\n",
       "      <td>37207.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>3205</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.727970e+06</td>\n",
       "      <td>686779.478089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25274</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>Curb/Trash miss Tuesday.</td>\n",
       "      <td>4028 Clarksville Pike</td>\n",
       "      <td>37218.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>4202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.721259e+06</td>\n",
       "      <td>685444.799565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25276</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>Curb/trash miss Tuesday.</td>\n",
       "      <td>6528 Thunderbird Dr</td>\n",
       "      <td>37209.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>4205</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.707027e+06</td>\n",
       "      <td>659887.471571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25307</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>missed</td>\n",
       "      <td>2603 old matthews rd</td>\n",
       "      <td>37207.0</td>\n",
       "      <td>WASTE IND</td>\n",
       "      <td>2206</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.735692e+06</td>\n",
       "      <td>685027.245923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25312</td>\n",
       "      <td>11/01/17</td>\n",
       "      <td>Trash - Curbside/Alley Missed Pickup</td>\n",
       "      <td>Missed the even side of the road.</td>\n",
       "      <td>604 croley dr</td>\n",
       "      <td>37209.0</td>\n",
       "      <td>RED RIVER</td>\n",
       "      <td>4203</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.710186e+06</td>\n",
       "      <td>664205.101066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Request Number Date Opened                              Request   \\\n",
       "0           25270    11/01/17                      Trash - Backdoor   \n",
       "1           25274    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "2           25276    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "3           25307    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "4           25312    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
       "\n",
       "                                         Description       Incident Address  \\\n",
       "0  house with the wheel chair ramp, they share dr...         3817 Crouch Dr   \n",
       "1                           Curb/Trash miss Tuesday.  4028 Clarksville Pike   \n",
       "2                           Curb/trash miss Tuesday.    6528 Thunderbird Dr   \n",
       "3                                             missed   2603 old matthews rd   \n",
       "4                  Missed the even side of the road.          604 croley dr   \n",
       "\n",
       "   Zip Code Trash Hauler Trash Route  Council District  State Plan X  \\\n",
       "0   37207.0    RED RIVER        3205               2.0  1.727970e+06   \n",
       "1   37218.0    RED RIVER        4202               1.0  1.721259e+06   \n",
       "2   37209.0    RED RIVER        4205              20.0  1.707027e+06   \n",
       "3   37207.0    WASTE IND        2206               2.0  1.735692e+06   \n",
       "4   37209.0    RED RIVER        4203              20.0  1.710186e+06   \n",
       "\n",
       "    State Plan Y  \n",
       "0  686779.478089  \n",
       "1  685444.799565  \n",
       "2  659887.471571  \n",
       "3  685027.245923  \n",
       "4  664205.101066  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "trash_df = pd.read_csv('../data/trash_hauler_report.csv')\n",
    "#Explore the data\n",
    "print(trash_df.shape)\n",
    "print(trash_df.columns)\n",
    "print(trash_df.dtypes)\n",
    "print(trash_df.info())\n",
    "trash_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ee677e4-ea30-4dc6-ada3-5426df83f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cleaned_missed_pickups = pd.read_csv('../data/cleaned_missed_pickups.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b005d40-55ab-4567-9067-9d7a63c851f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed extra spaces in some of the raw data, so this will clean up leading/trailing and extra spaces.\n",
    "\n",
    "#Clean only columns with object (string) type\n",
    "str_cols = trash_df.select_dtypes(include='object').columns\n",
    "\n",
    "#Clean and normalize whitespace in each string column\n",
    "for col in str_cols:\n",
    "    trash_df[col] = trash_df[col].astype(str).apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "#Clean column whitespace\n",
    "trash_df.columns = trash_df.columns.str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67339f44-3d1f-421a-a04a-edcea5c8261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Request\n",
       "Trash - Curbside/Alley Missed Pickup    15028\n",
       "Trash - Backdoor                         2629\n",
       "Trash Collection Complaint               2312\n",
       "Damage to Property                        257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make 'Request' column into a category\n",
    "trash_df['Request'] = trash_df['Request'].astype('category')\n",
    "trash_df['Request'].cat.categories\n",
    "trash_df['Request'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e39f62-349f-47b1-a0f3-aac657b428ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all lowercase so matches are consistent\n",
    "trash_df['description_clean'] = trash_df['Description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e17e34-c049-451a-997a-2d0c623de155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To help ensure data is complete, this creates a new Street Name column with only the street names (no address numbers)\n",
    "#Then if data is missing (Zip, Hauler, Route, District etc) it will complete the missing data based on the assumption that all addresses on the same street\n",
    "#uses the same Zip, Hauler, Route, District etc). It will complete any missing data for Incidents on the same Street Name.\n",
    "#It normalizes the new Street Name to USPS naming conventions so they can be easily grouped if needed.\n",
    "\n",
    "# USPS street suffix abbreviations\n",
    "suffix_map = {\n",
    "    'avenue': 'Ave', 'av': 'Ave', 'av.': 'Ave',\n",
    "    'road': 'Rd', 'rd': 'Rd',\n",
    "    'street': 'St', 'st': 'St',\n",
    "    'boulevard': 'Blvd', 'blvd': 'Blvd',\n",
    "    'drive': 'Dr', 'dr': 'Dr',\n",
    "    'court': 'Ct', 'ct': 'Ct',\n",
    "    'lane': 'Ln', 'ln': 'Ln',\n",
    "    'place': 'Pl', 'pl': 'Pl',\n",
    "    'circle': 'Cir', 'cir': 'Cir',\n",
    "    'trail': 'Trl', 'trl': 'Trl',\n",
    "    'parkway': 'Pkwy', 'pkwy': 'Pkwy',\n",
    "    'terrace': 'Ter', 'ter': 'Ter',\n",
    "    'way': 'Way',\n",
    "    'loop': 'Loop'\n",
    "}\n",
    "\n",
    "# USPS directional abbreviations\n",
    "direction_map = {\n",
    "    'north': 'N', 'n.': 'N', 'n': 'N',\n",
    "    'south': 'S', 's.': 'S', 's': 'S',\n",
    "    'east': 'E', 'e.': 'E', 'e': 'E',\n",
    "    'west': 'W', 'w.': 'W', 'w': 'W'\n",
    "}\n",
    "\n",
    "def normalize_street(address):\n",
    "    if pd.isnull(address):\n",
    "        return None\n",
    "\n",
    "    #Lowercase and remove house number\n",
    "    address = re.sub(r'^\\d+\\s*', '', address.strip().lower())\n",
    "\n",
    "    words = address.split()\n",
    "    result = []\n",
    "\n",
    "    for word in words:\n",
    "        #Remove punctuation\n",
    "        word = re.sub(r'[^\\w]', '', word)\n",
    "\n",
    "        #Normalize directionals first\n",
    "        if word in direction_map:\n",
    "            result.append(direction_map[word])\n",
    "        elif word in suffix_map:\n",
    "            result.append(suffix_map[word])\n",
    "        else:\n",
    "            result.append(word.capitalize())\n",
    "\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "trash_df['Street Name'] = trash_df['Incident Address'].astype(str).apply(\n",
    "    lambda x: re.sub(r'^\\d+\\s*', '', x.strip().lower()) if pd.notnull(x) else x\n",
    ")\n",
    "\n",
    "def safe_mode(series):\n",
    "    modes = series.mode()\n",
    "    return modes.iloc[0] if not modes.empty else None\n",
    "\n",
    "cols_to_infer = ['Zip Code', 'Trash Hauler', 'Trash Route', 'Council District']\n",
    "for col in cols_to_infer:\n",
    "    street_lookup = trash_df.groupby('Street Name')[col].agg(safe_mode)\n",
    "    trash_df[col] = trash_df[col].fillna(trash_df['Street Name'].map(street_lookup))\n",
    "\n",
    "\n",
    "#Creates new 'Street Name' column\n",
    "trash_df['Street Name'] = trash_df['Incident Address'].apply(normalize_street)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4d2471-11f8-4d9f-aae1-c829f60fe7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed that several other descriptions mention missed pickups in the Description column.\n",
    "#This is a list of keywords it finds in the event that the Request is not properly labeled as a Missed Pickup.\n",
    "#More keywords could be added if noticed in the raw data.\n",
    "\n",
    "import re\n",
    "\n",
    "keywords = [\n",
    "    'miss', 'missed', 'not picked up', 'not collected', 'no pickup',\n",
    "    'never came', 'did not collect', 'didn’t pick up', 'did not pick up'\n",
    "]\n",
    "\n",
    "pattern = '|'.join(re.escape(word) for word in keywords)\n",
    "\n",
    "is_missed_request = trash_df['Request'].str.contains(\"missed pickup\", case=False, na=False)\n",
    "is_missed_description = trash_df['description_clean'].str.contains(pattern, na=False)\n",
    "\n",
    "missed_pickups = trash_df[is_missed_request | is_missed_description]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cda4e75-2c80-4f81-a0d9-27398d35c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed that some entries seemed to be duplicates based on the date opened and the Incident Address in the raw data.\n",
    "#This filters out any Requests that may have been submitted multiple times for the same Date/Incident Address\n",
    "missed_pickups = missed_pickups.copy()\n",
    "missed_pickups['Date Opened'] = pd.to_datetime(\n",
    "    missed_pickups['Date Opened'], format='%m/%d/%y', errors='coerce'\n",
    ")\n",
    "\n",
    "unique_missed = missed_pickups.drop_duplicates(subset=['Incident Address', 'Date Opened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e1f661-5ed2-4234-b5b5-2e9c78aced45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I noticed some data was missing, i.e. Zip Code, Trash Hauler, Route, District etc.\n",
    "#This groups by the newly created 'Street Name' column and uses the infer data for the Street Name to fill in incomplete data if other instances of the same Street.\n",
    "cols_to_fill = ['Zip Code', 'Trash Hauler', 'Trash Route', 'Council District']\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    trash_df[col] = trash_df.groupby('Street Name')[col].transform(lambda x: x.ffill().bfill())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e780d93e-04ac-4aab-8fdf-42448478bf00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This exports the cleaned data to a CSV file. The output only includes unique missed pickups based on Request and/or keywords in Description columns.\n",
    "\n",
    "#Filter based on Request type or keywords in Description\n",
    "keywords = [\n",
    "    'miss', 'missed', 'not picked up', 'not collected', 'no pickup',\n",
    "    'never came', 'did not collect', 'didn’t pick up', 'did not pick up'\n",
    "]\n",
    "pattern = '|'.join(re.escape(word) for word in keywords)\n",
    "\n",
    "is_missed_request = trash_df['Request'].str.contains(\"missed pickup\", case=False, na=False)\n",
    "is_missed_description = trash_df['description_clean'].str.contains(pattern, na=False)\n",
    "\n",
    "missed_pickups = trash_df[is_missed_request | is_missed_description].copy()\n",
    "\n",
    "#Normalize data\n",
    "missed_pickups['Date Opened'] = pd.to_datetime(missed_pickups['Date Opened'], format='%m/%d/%y', errors='coerce')\n",
    "\n",
    "#Remove same-day duplicates\n",
    "unique_missed = missed_pickups.drop_duplicates(subset=['Incident Address', 'Date Opened']).copy()\n",
    "\n",
    "#Normalize Street Name\n",
    "unique_missed['Street Name'] = unique_missed['Incident Address'].apply(normalize_street)\n",
    "\n",
    "#Fill missing data based on same Street Names\n",
    "cols_to_fill = ['Zip Code', 'Trash Hauler', 'Trash Route', 'Council District']\n",
    "for col in cols_to_fill:\n",
    "    unique_missed[col] = unique_missed.groupby('Street Name')[col].transform(lambda x: x.ffill().bfill())\n",
    "    \n",
    "#Export to /data folder\n",
    "unique_missed.to_csv('./cleaned_missed_pickups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da0ce958-55f9-41fb-8476-f83e60286993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Request Number', 'Date Opened', 'Request', 'Description',\n",
      "       'Incident Address', 'Zip Code', 'Trash Hauler', 'Trash Route',\n",
      "       'Council District', 'State Plan X', 'State Plan Y', 'description_clean',\n",
      "       'Street Name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(trash_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4675439c-c8d3-434c-8008-94e36fd58eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Request Number', 'Date Opened', 'Request', 'Description', 'Incident Address', 'Zip Code', 'Trash Hauler', 'Trash Route', 'Council District', 'State Plan X', 'State Plan Y', 'description_clean', 'Street Name']\n"
     ]
    }
   ],
   "source": [
    "print(trash_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52862ef1-f138-435c-bc8b-c11cc8d5e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Request Number', 'Date Opened', 'Request', 'Description',\n",
      "       'Incident Address', 'Zip Code', 'Trash Hauler', 'Trash Route',\n",
      "       'Council District', 'State Plan X', 'State Plan Y', 'description_clean',\n",
      "       'Street Name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_missed_pickups.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ebc56b2-1aa9-4c05-a562-aefd06376791",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['fine', 'hauler', 'zip'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fines_by_address \u001b[38;5;241m=\u001b[39m \u001b[43mcleaned_missed_pickups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIncident Address\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhauler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\apply.py:190\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\apply.py:423\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\apply.py:1608\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1606\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1607\u001b[0m ):\n\u001b[1;32m-> 1608\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1611\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\apply.py:462\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m is_groupby \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    461\u001b[0m func \u001b[38;5;241m=\u001b[39m cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m--> 462\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m is_non_unique_col \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    465\u001b[0m     selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_obj\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    467\u001b[0m )\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\apply.py:663\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    661\u001b[0m     cols \u001b[38;5;241m=\u001b[39m Index(\u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;241m.\u001b[39mdifference(obj\u001b[38;5;241m.\u001b[39mcolumns, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 663\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    665\u001b[0m aggregator_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['fine', 'hauler', 'zip'] do not exist\""
     ]
    }
   ],
   "source": [
    "fines_by_address = cleaned_missed_pickups.groupby('Incident Address').agg({\n",
    "    'fine': 'first',\n",
    "    'zip': 'first',\n",
    "    'hauler': 'first'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1495d616-b5d2-4921-8418-573f19b163ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Request Number Date Opened                               Request  \\\n",
      "0               25270    11/01/17                      Trash - Backdoor   \n",
      "1               25274    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
      "2               25276    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
      "3               25307    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
      "4               25312    11/01/17  Trash - Curbside/Alley Missed Pickup   \n",
      "...               ...         ...                                   ...   \n",
      "20221          267125    11/01/19  Trash - Curbside/Alley Missed Pickup   \n",
      "20222          267126    11/01/19  Trash - Curbside/Alley Missed Pickup   \n",
      "20223          267130    11/01/19  Trash - Curbside/Alley Missed Pickup   \n",
      "20224          267134    11/01/19  Trash - Curbside/Alley Missed Pickup   \n",
      "20225          267137    11/01/19  Trash - Curbside/Alley Missed Pickup   \n",
      "\n",
      "                                             Description  \\\n",
      "0      house with the wheel chair ramp, they share dr...   \n",
      "1                               Curb/Trash miss Tuesday.   \n",
      "2                               Curb/trash miss Tuesday.   \n",
      "3                                                 missed   \n",
      "4                      Missed the even side of the road.   \n",
      "...                                                  ...   \n",
      "20221                          MISSED...NEIGHBORS MISSED   \n",
      "20222                                       entire alley   \n",
      "20223                                     missed several   \n",
      "20224  Caller stated trash was missed & were only pic...   \n",
      "20225                     possibly others missed as well   \n",
      "\n",
      "                                        Incident Address  Zip Code  \\\n",
      "0                                         3817 Crouch Dr   37207.0   \n",
      "1                                  4028 Clarksville Pike   37218.0   \n",
      "2                                    6528 Thunderbird Dr   37209.0   \n",
      "3                                   2603 old matthews rd   37207.0   \n",
      "4                                          604 croley dr   37209.0   \n",
      "...                                                  ...       ...   \n",
      "20221                             2731 Murfreesboro Pike   37013.0   \n",
      "20222  1621 Long Ave, Nashville, TN 37206, United States   37206.0   \n",
      "20223  2943 Windemere Cir, Nashville, TN 37214, Unite...   37214.0   \n",
      "20224  3325 Murfreesboro Pike, Nashville, TN 37013, U...   37013.0   \n",
      "20225  604 Somerset Ct, Nashville, TN 37217, United S...   37217.0   \n",
      "\n",
      "      Trash Hauler Trash Route  Council District  State Plan X   State Plan Y  \\\n",
      "0        RED RIVER        3205               2.0  1.727970e+06  686779.478089   \n",
      "1        RED RIVER        4202               1.0  1.721259e+06  685444.799565   \n",
      "2        RED RIVER        4205              20.0  1.707027e+06  659887.471571   \n",
      "3        WASTE IND        2206               2.0  1.735692e+06  685027.245923   \n",
      "4        RED RIVER        4203              20.0  1.710186e+06  664205.101066   \n",
      "...            ...         ...               ...           ...            ...   \n",
      "20221    RED RIVER        4502              32.0  1.781137e+06  632448.551144   \n",
      "20222        METRO        9508               6.0  1.749711e+06  669201.601569   \n",
      "20223    RED RIVER        1502              15.0  1.770293e+06  674936.303809   \n",
      "20224    RED RIVER        4502              32.0  1.785225e+06  627146.400187   \n",
      "20225    RED RIVER        2505              29.0  1.781360e+06  637742.006846   \n",
      "\n",
      "                                       description_clean  \\\n",
      "0      house with the wheel chair ramp, they share dr...   \n",
      "1                               curb/trash miss tuesday.   \n",
      "2                               curb/trash miss tuesday.   \n",
      "3                                                 missed   \n",
      "4                      missed the even side of the road.   \n",
      "...                                                  ...   \n",
      "20221                          missed...neighbors missed   \n",
      "20222                                       entire alley   \n",
      "20223                                     missed several   \n",
      "20224  caller stated trash was missed & were only pic...   \n",
      "20225                     possibly others missed as well   \n",
      "\n",
      "                                             Street Name  \n",
      "0                                              Crouch Dr  \n",
      "1                                       Clarksville Pike  \n",
      "2                                         Thunderbird Dr  \n",
      "3                                        Old Matthews Rd  \n",
      "4                                              Croley Dr  \n",
      "...                                                  ...  \n",
      "20221                                  Murfreesboro Pike  \n",
      "20222          Long Ave Nashville Tn 37206 United States  \n",
      "20223     Windemere Cir Nashville Tn 37214 United States  \n",
      "20224  Murfreesboro Pike Nashville Tn 37013 United St...  \n",
      "20225       Somerset Ct Nashville Tn 37217 United States  \n",
      "\n",
      "[20226 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trash_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a10724-8aad-4c79-9128-767de6455cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-geospatial] *",
   "language": "python",
   "name": "conda-env-anaconda3-geospatial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
